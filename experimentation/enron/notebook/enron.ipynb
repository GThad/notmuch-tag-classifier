{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enron Classifier Test\n",
    "\n",
    "This notebook gives the Python code for our initial tests of building a classifier with scikit-learn and the labelled Enron email database from Berkeley.\n",
    "\n",
    "First we need to get to the folder where the emails are stores and get the list of emails (.txt) and their corresponding category files (.cats) and create tuples out of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD is /home/gif/Desktop/scikit-learn-tests/enron_notebook\n",
      "Email Directory is /home/gif/Desktop/scikit-learn-tests/enron_emails\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import re\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(\"CWD is {}\".format(cwd))\n",
    "cwdList = cwd.split(\"/\")\n",
    "enronWd = \"/\".join(cwdList[0:-1] + [\"enron_emails\"])\n",
    "os.chdir(enronWd)\n",
    "print(\"Email Directory is {}\".format(enronWd))\n",
    "\n",
    "fileList = os.listdir()\n",
    "emailFileList = [file for file in fileList\n",
    "                 if fnmatch.fnmatch(file, \"*.txt\")]\n",
    "catFileList = [file for file in fileList\n",
    "               if fnmatch.fnmatch(file, \"*.cats\")]\n",
    "\n",
    "emailFileList.sort()\n",
    "catFileList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check for pairwise matching of email and cat IDs\n",
    "for email, cat in zip(emailFileList, catFileList):\n",
    "    emailID = email.split(\".\")[0]\n",
    "    catID = cat.split(\".\")[0]\n",
    "    if(emailID != catID):\n",
    "        print(\"ERROR: emailID {} differs from catID {}\".\n",
    "               format(emailID, catID))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Okay now that we have our email file and corresponding category file strings in tuples, we can begin reading the data in. For now each we will read each email in as a 4 tuple (w,x,y,z) where w is the ID, x is the email headers, y is the email message, and z is a list of tags associated with it. Since we use a slightly modified tagging system than the database, we need to translate their tags to our tags. First we initalize the ranaming dictionary and then create the list of 4 tuples.\n",
    "\n",
    "Note they use the word \"cat\" for labels, we use the word \"tag\". This is convenient to distinguish their labels from ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note their categories are in the form \"x,y,z\". We use z = 2\n",
    "# to ensure both labellers agreed.\n",
    "catToTagID = {\"1,1,2\": 1,   \"1,3,2\": 2,   \"3,1,2\": 3,   \"3,2,2\": 4,\n",
    "              \"3,3,2\": 5,   \"3,3,2\": 6,   \"3,4,2\": 5,   \"3,4,2\": 7,\n",
    "              \"3,5,2\": 8,   \"3,6,2\": 9,   \"3,7,2\": 10,  \"3,7,2\": 11,\n",
    "              \"3,8,2\": 10,  \"3,8,2\": 12,  \"3,9,2\": 13,  \"3,10,2\": 14,\n",
    "              \"3,11,2\": 15, \"3,12,2\": 16, \"3,13,2\": 17, \"1,2,2\": 18,\n",
    "              \"1,4,2\": 19,  \"1,5,2\": 20,  \"1,6,2\": 21,  \"1,7,2\": 22,\n",
    "              \"1,8,2\": 22,  \"2,4,2\": 23,  \"2,5,2\": 24,  \"2,5,2\": 25,\n",
    "              \"2,6,2\": 24,  \"2,6,2\": 26,  \"2,7,2\": 27,  \"2,10,2\": 28,\n",
    "              \"2,11,2\": 29, \"2,12,2\": 29}\n",
    "tagIDToTagName = {1: \"company\", 2: \"company-personal\",\n",
    "                  3: \"company-regulations\", 4: \"company-strategy\",\n",
    "                  5: \"company-image\", 6: \"company-image-current\",\n",
    "                  7: \"company-image-future\", 8: \"company-contributers\",\n",
    "                  9: \"company-california-crisis\", 10: \"company-internal\",\n",
    "                  11: \"company-internal-policy\", 12: \"company-internal-operations\",\n",
    "                  13: \"company-allies\", 14: \"company-legal\",\n",
    "                  15: \"company-talk-points\", 16: \"company-minutes\",\n",
    "                  17: \"company-trip-reports\", 18: \"personal\",\n",
    "                  19: \"logistics\", 20: \"career\", 21: \"collaboration\", \n",
    "                  22: \"empty\", 22: \"empty\", 23: \"news-article\", 24: \"gov\",\n",
    "                  25: \"gov-report\", 26: \"gov-action\", 27: \"press-release\",\n",
    "                  28: \"newsletter\", 29: \"joke\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailTuples = list()\n",
    "\n",
    "for emailFile, catFile in zip(emailFileList, catFileList):\n",
    "    emailID = int(emailFile.split(\".\")[0])\n",
    "    with open(emailFile, \"r\") as email:\n",
    "        emailLines = email.readlines()\n",
    "        headerSepIndex = emailLines.index(\"\\n\")\n",
    "        headers = \"\".join(emailLines[:headerSepIndex])\n",
    "        msg = \"\".join(emailLines[headerSepIndex + 1:])\n",
    "    with open(catFile, \"r\") as cats:\n",
    "        tags = list()\n",
    "        for cat in cats:\n",
    "            cat = cat.rstrip(\"\\n\")\n",
    "            if cat in catToTagID:\n",
    "                tags.append(catToTagID[cat])\n",
    "    \n",
    "    emailTuples.append((emailID, headers, msg, tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the emails in tuples, we have to remove the ones without any tags in them.\n",
    "\n",
    "Possible issue: apparently running the code below multiple times only gets rid of all the tagless emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306\n"
     ]
    }
   ],
   "source": [
    "for email in emailTuples:\n",
    "    if not email[3]:\n",
    "        emailTuples.remove(email)\n",
    "        \n",
    "print(len(emailTuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output, it seems we went from our original 1702 emails to 1181 for our dataset. Now we are tasked with putting these into a Pandas data frame. By using a data frame, we will be able to better analyze the data and convert it into a form usable by scikit-learn.\n",
    "\n",
    "The biggest challenge will be converting each email message into the features we need Our best bet will be to take the message part of each tuple and then operate on it to create a list of features. Then replace the message in the tuple with the list of features.\n",
    "\n",
    "First we have to generate our bag-of-words. We can do this with scikit-learn text vectorizers, which take a list of strings and create bag-of-words models for them. Looking at the source code, it seems the default processor only removes accents and makes terms lowercase. We need to these both and remove certain words from the message which do not appear in natural text.\n",
    "\n",
    "These include numbers or odd strings like \"xyz=abc\" or links or file paths of some sort -- really anything that isn't prose. Essentially, we want to remove non alphabet characters from each message, but we need to be careful about this. Whenever a non-alphabet character separates two actual words (like in links), we create a long unnatural word when we remove such characters.\n",
    "\n",
    "Perhaps a good heuristic to use would be to split any word on its non-alphabet characters, and then add the resulting words to the word bag.\n",
    "\n",
    "Our preprocessor should take the message and remove/fix all instances of these odd strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Expects a string msg\n",
    "def cleanMsg(msg):\n",
    "    words = msg.split(\" \")\n",
    "    words[:] = [re.split(\"[^a-z|A-Z]\", word) for word in words]\n",
    "    words[:] = [word for sublist in words for word in sublist]\n",
    "    words[:] = [word for word in words if word is not \"\"]\n",
    "    words = [word.lower() for word in words]\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now that we have the preprocessor built, we can try building part of entire data set. The part we are building will simply be the word features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as vectorizers\n",
    "\n",
    "vectorizer = vectorizers.TfidfVectorizer(\n",
    "                   input=\"content\", encoding=\"utf-8\", \n",
    "                   decode_error=\"strict\", preprocessor=cleanMsg, \n",
    "                   analyzer=\"word\", stop_words=None, \n",
    "                   ngram_range=(1, 1), max_df=1.0, \n",
    "                   min_df=1, max_features=None, \n",
    "                   vocabulary=None, \n",
    "                   norm=\"l2\", use_idf=True, \n",
    "                   smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "msgList = [email[2] for email in emailTuples]\n",
    "data = vectorizer.fit_transform(msgList[0:20])\n",
    "featureNames = vectorizer.get_feature_names()\n",
    "wordToColIndex = {word: vectorizer.vocabulary_.get(word)\n",
    "                  for word in featureNames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our word features. But we have features we can extract from the headers too. Let's get them. We can use another vectorizer for this if we can get seach instance into dictionary form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to loop over the emails and create rows for the data frame. Each row refers to a different email and the columns are:\n",
    "\n",
    "EmailID, Date, From, To, {Word Features}, {Tags}\n",
    "\n",
    "EmailID will be an integer.\n",
    "Date will need to be converted to some integral form.\n",
    "From will be a string.\n",
    "To will be a string.\n",
    "{Word Features} will be integers, with tfidf values.\n",
    "{Tags} will be integers, one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeader(header, key):\n",
    "    headerWithKey = [line for line in header \n",
    "                     if re.match(key, line)]\n",
    "    value = headerWithKey[0].split(\":\")[1].strip()\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailRowList = list()\n",
    "\n",
    "for email in emailTuples[0:10]:\n",
    "    featureTuple = ()\n",
    "    emailID = email[0]\n",
    "    emailDate = getHeader(email[1], \"Date\")\n",
    "    emailFrom = getHeader(email[1], \"From\")\n",
    "    emailTo = getHeader(email[1], \"To\")\n",
    "    featureTuple = featureTuple + (emailID, emailDate, emailFrom, \n",
    "                                   emailTo,)\n",
    "    \n",
    "    msgBag = cleanBag(makeBag(email[2]))\n",
    "    for word in wordBag:\n",
    "        if word in msgBag:\n",
    "            featureTuple = featureTuple + (1,)\n",
    "        else:\n",
    "            featureTuple = featureTuple + (0,)\n",
    "    \n",
    "    emailRowList.append(featureTuple)\n",
    "\n",
    "print(emailRowList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
